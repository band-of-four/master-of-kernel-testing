{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Purpose\n",
    "\n",
    "Our framework is primarily intended for testing OpenCL implementations of common machine learning operations and (possibly even) hand-written networks. For now, we're going to consider them as _pure functions_, with the return value depending solely on the arguments. To test them, we gather a set of input-output pairs, feed the inputs, and compare results with the corresponding outputs.\n",
    "\n",
    "Gathering data presents the biggest challenge: it needs to be both truthful and varied, dimensions-wise and content-wise. Accumulating it by hand is error-prone and time-consuming; so is writing generators (essentially, host-based implementations of target operations).\n",
    "\n",
    "Instead, we choose to extract inputs and outputs from a TensorFlow _computational graph_. Its primitive operations are well-tested, and as such can be used to verify new implementations. Moreover, data can be dumped for a subgraph instead of a single node, allowing fused operations (e.g. batch normalization and ReLU activation combined) to be tested as well.\n",
    "\n",
    "# Importing a Graph\n",
    "\n",
    "We envision that users would want to work with existing models, such as the [officially supported ones](https://github.com/tensorflow/models). This is achieved by loading a computational graph from a saved [checkpoint](https://www.tensorflow.org/guide/checkpoints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_graph_from_checkpoint(sess, chkpt_dir):\n",
    "  latest_chkpt = tf.train.latest_checkpoint(chkpt_dir)\n",
    "  \n",
    "  saver = tf.train.import_meta_graph(f'{latest_chkpt}.meta')\n",
    "  saver.restore(sess, latest_chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_and_extract(sess, inputs, output_node_names):\n",
    "  outputs = [tf.get_default_graph().get_tensor_by_name(n) for n in output_node_names]\n",
    "  return sess.run(outputs, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `inputs` is a dictionary of tensor names to tensors, which provides input values for the _whole model_. For the purposes of testing, the tensors can be randomly generated as long as we know their names, and those can be extracted using `tf.report_uninitialized_variables()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_inputs(sess):\n",
    "  input_tensor_names = [f'{str(v, \"utf8\")}:0' for v in sess.run(tf.report_uninitialized_variables())]\n",
    "  return {n: sess.run(tf.random_uniform(tf.get_default_graph().get_tensor_by_name(n).shape))\n",
    "          for n in input_tensor_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring Desired Outputs\n",
    "\n",
    "To reduce the amount of boilerplate code required to run the tests, we use _function decorators_ to specify target outputs in a declarative fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "class FeedTensors(object):\n",
    "  def __init__(self, checkpoint_dir, tensors):\n",
    "    output_names, output_nodes = np.array(list(tensors.items())).transpose().tolist()\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    load_graph_from_checkpoint(sess, checkpoint_dir)\n",
    "    inputs = random_inputs(sess)\n",
    "    output_values = run_model_and_extract(sess, inputs, output_nodes)\n",
    "    \n",
    "    self.data = dict(zip(output_names, output_values))\n",
    "  \n",
    "  def __call__(self, fn):\n",
    "    @functools.wraps(fn)\n",
    "    def with_inputs(*args, **kwargs):\n",
    "        kwargs['inputs'] = self.data\n",
    "        fn(*args, **kwargs)\n",
    "    return with_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "The checkpoint used as an example was created using [TensorFlow benchmarking scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks#tf_cnn_benchmarks-high-performance-benchmarks):\n",
    "\n",
    "```\n",
    "CHKPT_DIR='../../Documents/resnet50v1_traindir'\n",
    "\n",
    "python3 tf_cnn_benchmarks.py --model=resnet50 --data_format=NHWC --batch_size=8 --num_batches=1 \\\n",
    "  --train_dir=${CHKPT_DIR} --trace_file=${CHKPT_DIR}/trace --tfprof_file=${CHKPT_DIR}/profile \\\n",
    "  --summary_verbosity=3 --save_summaries_steps=30 \\\n",
    "  --device=cpu --local_parameter_device=cpu --all_reduce_spec=pscpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../Documents/resnet50v1_traindir/model.ckpt-11\n",
      "{'add': (8, 56, 56, 256), 'relu': (8, 56, 56, 256)}\n"
     ]
    }
   ],
   "source": [
    "@FeedTensors(checkpoint_dir='../../Documents/resnet50v1_traindir',\n",
    "             tensors={'add': 'v/tower_0/cg/resnet_v10/add:0', 'relu': 'v/tower_0/cg/resnet_v10/Relu:0'})\n",
    "def test(inputs):\n",
    "  print({k: v.shape for (k, v) in inputs.items()})\n",
    "  \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
