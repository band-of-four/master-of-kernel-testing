{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Purpose\n",
    "\n",
    "Our framework is primarily intended for testing OpenCL implementations of common machine learning operations and (possibly even) hand-written networks. For now, we're going to consider them as _pure functions_, with the return value depending solely on the arguments. To test them, we gather a set of input-output pairs, feed the inputs, and compare results with the corresponding outputs.\n",
    "\n",
    "Gathering data presents the biggest challenge: it needs to be both truthful and varied, dimensions-wise and content-wise. Accumulating it by hand is error-prone and time-consuming; so is writing generators (essentially, host-based implementations of target operations).\n",
    "\n",
    "Instead, we choose to extract inputs and outputs from a TensorFlow _computational graph_. Its primitive operations are well-tested, and as such can be used to verify new implementations. Moreover, data can be dumped for a subgraph instead of a single node, allowing fused operations (e.g. batch normalization and ReLU activation combined) to be tested as well.\n",
    "\n",
    "# Importing a Graph\n",
    "\n",
    "We envision that users would want to work with existing models, such as the [officially supported ones](https://github.com/tensorflow/models). This is achieved by loading a computational graph from a saved [checkpoint](https://www.tensorflow.org/guide/checkpoints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_graph_from_checkpoint(sess, chkpt_dir):\n",
    "  latest_chkpt = tf.train.latest_checkpoint(chkpt_dir)\n",
    "  \n",
    "  saver = tf.train.import_meta_graph(f'{latest_chkpt}.meta')\n",
    "  saver.restore(sess, latest_chkpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_and_extract(sess, inputs, output_node_names):\n",
    "  outputs = [tf.get_default_graph().get_tensor_by_name(n) for n in output_node_names]\n",
    "  return sess.run(outputs, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `inputs` is a dictionary of tensor names to tensors, which provides input values for the _whole model_. For the purposes of testing, the tensors can be randomly generated as long as we know their names, and those can be extracted using `tf.report_uninitialized_variables()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_inputs(sess):\n",
    "  input_tensor_names = [f'{str(v, \"utf8\")}:0' for v in sess.run(tf.report_uninitialized_variables())]\n",
    "  return {n: sess.run(tf.random_uniform(tf.get_default_graph().get_tensor_by_name(n).shape))\n",
    "          for n in input_tensor_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching Values\n",
    "\n",
    "If you relaunch the notebook, you may notice that it takes a few seconds for TensorFlow to restore the graph, run it, and dump the data we're interested in. This is an unacceptable delay for frequently run tests; to counter it, we may cache tensors on disk (serialized in a binary NumPy format) and only call TensorFlow routines if we need them.\n",
    "\n",
    "A unique storage name is needed for each cached value. We've chosen a SHA-256 hash of the checkpoint path and full node name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha256\n",
    "import os\n",
    "\n",
    "def cache_filename(checkpoint_dir, node_name):\n",
    "  return sha256(f'{checkpoint_dir}//{node_name}'.encode('utf8')).hexdigest() + '.npy'\n",
    "\n",
    "def restore_cached(checkpoint_dir, node_names):\n",
    "  os.makedirs('__testdumps__', exist_ok=True)\n",
    "  cached_filenames = os.listdir('__testdumps__')\n",
    "  \n",
    "  nodes = [(node_name, cache_filename(checkpoint_dir, node_name)) for node_name in node_names]\n",
    "  return {node_name: np.load('__testdumps__/' + cache_name)\n",
    "          if cache_name in cached_filenames else None\n",
    "          for (node_name, cache_name) in nodes}\n",
    "\n",
    "def cache_outputs(checkpoint_dir, node_names_to_tensors):\n",
    "  for (node_name, tensor) in node_names_to_tensors.items():\n",
    "    np.save('__testdumps__/' + cache_filename(checkpoint_dir, node_name), tensor)\n",
    "\n",
    "def compute_outputs_with_cache(checkpoint_dir, node_names):\n",
    "  restored = restore_cached(checkpoint_dir, node_names)\n",
    "  cache_misses = [node_name for (node_name, tensor) in restored.items() if tensor is None]\n",
    "  \n",
    "  if len(cache_misses) == 0:\n",
    "    return restored\n",
    "  \n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.Session()\n",
    "  \n",
    "  load_graph_from_checkpoint(sess, checkpoint_dir)\n",
    "  inputs = random_inputs(sess)\n",
    "  output_values = run_model_and_extract(sess, inputs, cache_misses)\n",
    "  \n",
    "  computed = dict(zip(cache_misses, output_values))\n",
    "  cache_outputs(checkpoint_dir, computed)\n",
    "  \n",
    "  return {**restored, **computed}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring Desired Outputs\n",
    "\n",
    "To reduce the amount of boilerplate code required to run the tests, we use _function decorators_ to specify target outputs in a declarative fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "class FeedTensors(object):\n",
    "  def __init__(self, checkpoint_dir, test_values):\n",
    "    output_node_names = list(test_values.values())    \n",
    "    outputs = compute_outputs_with_cache(checkpoint_dir, output_node_names)\n",
    "    \n",
    "    self.test_values = {output_name: outputs[output_node_name]\n",
    "                        for (output_name, output_node_name) in test_values.items()}\n",
    "  \n",
    "  def __call__(self, fn):\n",
    "    @functools.wraps(fn)\n",
    "    def with_inputs(*args, **kwargs):\n",
    "        kwargs['test_values'] = self.test_values\n",
    "        fn(*args, **kwargs)\n",
    "    return with_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "The checkpoint used as an example was created using [TensorFlow benchmarking scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks#tf_cnn_benchmarks-high-performance-benchmarks):\n",
    "\n",
    "```\n",
    "CHKPT_DIR='../../Documents/resnet50v1_traindir'\n",
    "\n",
    "python3 tf_cnn_benchmarks.py --model=resnet50 --data_format=NHWC --batch_size=8 --num_batches=1 \\\n",
    "  --train_dir=${CHKPT_DIR} --trace_file=${CHKPT_DIR}/trace --tfprof_file=${CHKPT_DIR}/profile \\\n",
    "  --summary_verbosity=3 --save_summaries_steps=30 \\\n",
    "  --device=cpu --local_parameter_device=cpu --all_reduce_spec=pscpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'add': (8, 56, 56, 256), 'relu': (8, 56, 56, 256)}\n"
     ]
    }
   ],
   "source": [
    "@FeedTensors(checkpoint_dir='../../Documents/resnet50v1_traindir',\n",
    "             test_values={'add': 'v/tower_0/cg/resnet_v10/add:0', 'relu': 'v/tower_0/cg/resnet_v10/Relu:0'})\n",
    "def test(test_values):\n",
    "  print({k: v.shape for (k, v) in test_values.items()})\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
